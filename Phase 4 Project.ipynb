{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 4 Project - NLP\n",
    "Julia Müller\n",
    "\n",
    "Data Science Flex\n",
    "\n",
    "## Summary abstract\n",
    "\n",
    "For my Natural Language Processing project, I am using a dataset from CrowdFlower including more than 9000 Tweets about Apple and Google products. For my business problem, it is well suited because I can advise Google and Apple about which features or activities create positive sentiment to that they can leverage it better. The data set is unbalanced with around 35% of the Tweets being positive, 7% negative and more than 50% neutral or undefined.\n",
    "After basic data cleaning activities, I removed basic stop words as well as product specific words and used Tokenization from TweetTokenizer and WordNetLemmatizer from NLTK which are suitable for handling tweets taking care of # and mentions.\n",
    "For modeling, I mainly used sklearn libraries and libraries from imblearn to address the class imbalance. Also, I recategorized to have a binary classifier (positive sentiment vs. non-positive including neutrals and negatives). I started with a baseline logistic regression model, tuned it by removing stopwords, lemmatization and tokenization. Furthermore, I applied a random forest model and tuned it with the same steps. For both models, I applied hyperparameter tuning using sklearn’s GridSearchCv. My final model is a tuned random forest model with CountVectorizer, random oversampling and specified parameters such as minimum sample leafs, minimum sample split and the number of estimators.\n",
    "My final model has a weighted average precision of .73. When my model predicts positive cases, it is correct 76% of the time which is acceptable. A limitation is that the model is not as great in predicting non-positive sentiments. We can improve the model by collecting more data. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction & Business Problem\n",
    "In today's highly competitive digital landscape, understanding and managing brand perception is paramount for sustained success. Our client, a leading technology company, faces the challenge of effectively gauging public sentiment towards their products in real time. With a massive volume of customer-generated content on social media platforms, particularly Twitter, the client is seeking to harness the power of data science to gain actionable insights from this unstructured data. The business problem at hand revolves around the need to develop an accurate sentiment analysis model capable of classifying tweets related to their products—specifically Apple and Google offerings—as either positive or negative. By doing so, our client aims to proactively identify areas of concern, measure the impact of product launches, marketing campaigns, and other business initiatives, and ultimately refine their strategies to enhance customer satisfaction and loyalty. This project serves as a strategic tool to transform raw social media data into valuable insights, enabling our client to stay ahead in a dynamic and ever-evolving market.\n",
    "For my model evaluation, I will prioritize to correctly identify positive tweets and therefore minimizing false positives. I want to ensure that tweets with positive sentiment are correctly classified as such even if it means potentially having more false negatives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Collection & Understanding\n",
    "First, I will load the required packages and then load and familiarize myself with the data. I will look at the first 100 columns to get a feeling about the content of the tweets, the structure of the data (columns and missing values etc)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading required packages\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "#train test split and undersampling\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "#packages for preprocessing\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "import string\n",
    "from nltk import FreqDist\n",
    "#packages for modeling and feature selection\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "#model evaluation\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay, RocCurveDisplay, roc_curve, auc\n",
    "from sklearn.metrics import precision_score, accuracy_score, recall_score, f1_score\n",
    "import warnings\n",
    "# Suppress all warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "#nltk.download('punkt')\n",
    "#nltk.download('stopwords')\n",
    "#nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read data\n",
    "df = pd.read_csv(\"data/tweets.csv\", encoding=\"latin-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9093 entries, 0 to 9092\n",
      "Data columns (total 3 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   Tweet          9092 non-null   object\n",
      " 1   Brand/Product  3291 non-null   object\n",
      " 2   Emotion        9093 non-null   object\n",
      "dtypes: object(3)\n",
      "memory usage: 213.2+ KB\n"
     ]
    }
   ],
   "source": [
    "# Set display options to show all rows and increase the column width\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#simplify column names\n",
    "df.columns = ['Tweet','Brand/Product','Emotion']\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Brand/Product</th>\n",
       "      <th>Emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs tweeting at #RISE_Austin, it was dead!  I need to upgrade. Plugin stations at #SXSW.</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee Know about @fludapp ? Awesome iPad/iPhone app that you'll likely appreciate for its design. Also, they're giving free Ts at #SXSW</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin Can not wait for #iPad 2 also. They should sale them down at #SXSW.</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sxsw I hope this year's festival isn't as crashy as this year's iPhone app. #sxsw</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa Mayer (Google), Tim O'Reilly (tech books/conferences) &amp;amp; Matt Mullenweg (Wordpress)</td>\n",
       "      <td>Google</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>@teachntech00 New iPad Apps For #SpeechTherapy And Communication Are Showcased At The #SXSW Conference http://ht.ly/49n4M #iear #edchat #asd</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>#SXSW is just starting, #CTIA is around the corner and #googleio is only a hop skip and a jump from there, good time to be an #android fan</td>\n",
       "      <td>Android</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Beautifully smart and simple idea RT @madebymany @thenextweb wrote about our #hollergram iPad app for #sxsw! http://bit.ly/ieaVOB</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Counting down the days to #sxsw plus strong Canadian dollar means stock up on Apple gear</td>\n",
       "      <td>Apple</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Excited to meet the @samsungmobileus at #sxsw so I can show them my Sprint Galaxy S still running Android 2.1.   #fail</td>\n",
       "      <td>Android</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Find &amp;amp; Start Impromptu Parties at #SXSW With @HurricaneParty http://bit.ly/gVLrIn I can't wait til the Android app comes out.</td>\n",
       "      <td>Android App</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Foursquare ups the game, just in time for #SXSW http://j.mp/grN7pK) - Still prefer @Gowalla by far, best looking Android app to date.</td>\n",
       "      <td>Android App</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Gotta love this #SXSW Google Calendar featuring top parties/ show cases to check out.  RT @hamsandwich via @ischafer =&amp;gt;http://bit.ly/aXZwxB</td>\n",
       "      <td>Other Google product or service</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Great #sxsw ipad app from @madebymany: http://tinyurl.com/4nqv92l</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>haha, awesomely rad iPad app by @madebymany http://bit.ly/hTdFim #hollergram #sxsw</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Holler Gram for iPad on the iTunes App Store -  http://t.co/kfN3f5Q (via @marc_is_ken) #sxsw</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>I just noticed DST is coming this weekend. How many iPhone users will be an hour late at SXSW come Sunday morning? #SXSW #iPhone</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Just added my #SXSW flights to @planely. Matching people on planes/airports. Also downloaded the @KLM iPhone app, nicely done.</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Must have #SXSW app! RT @malbonster: Lovely review from Forbes for our SXSW iPad app Holler Gram - http://t.co/g4GZypV</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Need to buy an iPad2 while I'm in Austin at #sxsw. Not sure if I'll need to Q up at an Austin Apple store?</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Oh. My. God. The #SXSW app for iPad is pure, unadulterated awesome. It's easier to browse events on iPad than on the website!!!</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Okay, this is really it: yay new @Foursquare for #Android app!!!!11 kthxbai. #sxsw</td>\n",
       "      <td>Android App</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Photo: Just installed the #SXSW iPhone app, which is really nice! http://tumblr.com/x6t1pi6av7</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Really enjoying the changes in Gowalla 3.0 for Android! Looking forward to seeing what else they &amp;amp; Foursquare have up their sleeves at #SXSW</td>\n",
       "      <td>Android App</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>RT @LaurieShook: I'm looking forward to the #SMCDallas pre #SXSW party Wed., and hoping I'll win an #iPad resulting from my shameless promotion.  #ChevySMC</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>RT haha, awesomely rad iPad app by @madebymany http://bit.ly/hTdFim #hollergram #sxsw (via @michaelpiliero)</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>someone started an #austin @PartnerHub group in google groups, pre-#sxsw. great idea</td>\n",
       "      <td>Other Google product or service</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>The new #4sq3 looks like it is going to rock. Update for iPhone and Android should push tonight http://bit.ly/etsbZk #SXSW #KeepAustinWeird</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>They were right, the @gowalla 3 app on #android is sweeeeet! Nice job by the team there. #sxsw</td>\n",
       "      <td>Android App</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Very smart from @madebymany #hollergram iPad app for #sxsw! http://t.co/A3xvWc6 (may leave my vuvuzela at home now)</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>You must have this app for your iPad if you are going to #SXSW http://itunes.apple.com/us/app/holler-gram/id420666439?mt=8 #hollergram</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Attn: All  #SXSW frineds, @mention Register for #GDGTLive  and see Cobra iRadar for Android. {link}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Anyone at  #sxsw want to sell their old iPad?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Anyone at  #SXSW who bought the new iPad want to sell their older iPad to me?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>At #sxsw.  Oooh. RT @mention Google to Launch Major New Social Network Called Circles, Possibly Today {link}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>The best!  RT @mention Ha! First in line for #ipad2 at #sxsw &amp;quot;pop-up&amp;quot; Apple store was an event planner #eventprofs #pcma #engage365</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>SPIN Play - a new concept in music discovery for your iPad from @mention &amp;amp; spin.com {link} #iTunes #sxsw @mention</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>@mention  - False Alarm: Google Circles Not Coming NowÛÒand Probably Not Ever? - {link} #Google #Circles #Social #SXSW</td>\n",
       "      <td>Google</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>VatorNews - Google And Apple Force Print Media to Evolve? {link} #sxsw</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>@mention  - Great weather to greet you for #sxsw! Still need a sweater at night..Apple putting up &amp;quot;flash store&amp;quot; downtown to sell iPad2</td>\n",
       "      <td>Apple</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>HootSuite - HootSuite Mobile for #SXSW ~ Updates for iPhone, BlackBerry &amp;amp; Android: Whether youÛªre getting friend... {link}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Hey #SXSW - How long do you think it takes us to make an iPhone case? answer @mention using #zazzlesxsw and weÛªll make you one!</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Mashable! - The iPad 2 Takes Over SXSW [VIDEO] #ipad #sxsw #gadgets {link}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>For I-Pad ?RT @mention New #UberSocial for #iPhone now in the App Store includes UberGuide to #SXSW sponsored by ... {link}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>#IPad2 's Û÷#SmartCoverÛª Opens to Instant Access - I should have waited to get one! - {link} #apple #SXSW</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Hand-Held Û÷HoboÛª: Drafthouse launches Û÷Hobo With a ShotgunÛª iPhone app #SXSW {link}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>HOORAY RT ÛÏ@mention Apple Is Opening A Pop-Up Store In Austin For #SXSW | @mention {link}</td>\n",
       "      <td>Apple</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Orly....? ÛÏ@mention Google set to launch new social network #Circles today at #sxswÛ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>wooooo!!! ÛÏ@mention Apple store downtown Austin open til Midnight. #sxswÛ</td>\n",
       "      <td>Apple</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Khoi Vinh (@mention says Conde Nast's headlong rush into iPad publishing was a &amp;quot;fundamental misunderstanding&amp;quot; of the platform #sxsw</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>ÛÏ@mention {link} &amp;lt;-- HELP ME FORWARD THIS DOC to all Anonymous accounts, techies,&amp;amp; ppl who can help us JAM #libya #SXSW</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>÷¼ WHAT? ÷_ {link} ã_ #edchat #musedchat #sxsw #sxswi #classical #newTwitter</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>.@mention @mention on the location-based 'fast, fun and future' - {link} (via @mention #sxsw</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>ÛÏ@mention @mention #Google Will Connect the Digital &amp;amp; Physical Worlds Through Mobile - {link} #sxswÛ @mention</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>ÛÏ@mention @mention talking about {link} - Google's effort to allow users to have open systems #bettercloud #sxswÛ</td>\n",
       "      <td>Google</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>{link} RT @mention &amp;quot;Google before you tweet&amp;quot; is the new &amp;quot;think before you speak.&amp;quot; - Mark Belinsky, #911tweets panel at #SXSW.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>{link} RT @mention 1st stop on the #SXSW #Chaos &amp;amp; @mention hunt: Austin Java. Get in the spy game 4 a chance 2 win an iPad!</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>{link} RT @mention Those at #SXSW check out the Holler Gram ipad app from @mention  {link}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>@mention  @mention &amp;amp;  @mention having fun at #google [pic] #SXSW {link}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>&amp;quot;via @mention : {link} Guy Kawasaki talks 'Enchanted' at SXSW - HE knows his stuff! #books #internet #Apple #sxsw  &amp;quot;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>#futuremf @mention {link} spec for recipes on the web, now in google search: {link}  #sxsw</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>#OMFG! RT @mention Heard about Apple's pop-up store in downtown Austin? Pics are already on Gowalla: {link} #sxsw #iPad2</td>\n",
       "      <td>Apple</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>#Smile RT @mention I think Apple's &amp;quot;pop-up store&amp;quot; in Austin would be a lot more interesting if it actually, you know... popped up #sxsw</td>\n",
       "      <td>Apple</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>Again? RT @mention Line at the Apple store is insane.. #sxsw</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>Agree. RT @mention Wait. FIONA APPLE is in town??? Somebody kidnap her and put her in a recording studio until she records a new album. #sxsw</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>At #sxsw? @mention / @mention wanna buy you a drink. 7pm at Fado on 4th. {link} Join us!</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>attending @mention iPad design headaches #sxsw {link}</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>Boooo! RT @mention Flipboard is developing an iPhone version, not Android, says @mention #sxsw</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>Check out @mention @mention &amp;amp; @mention in line for their iPad 2 in Austin. Power to them! #sxswi #SXSW  {link}</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>Check! RT @mention giving added value to location based services needs to battle check-in fatigue #google #pnid #sxsw</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>Chilcott: @mention #SXSW stand talking with Blogger staff. Too late to win competition for best tweet mentioning @mention So no t-shirt.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>Do it. RT @mention Come party w/ Google tonight at #sxsw! {link} - Bands, food, art, ice cream, nifty interactive maps!</td>\n",
       "      <td>Google</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>Gowalla's @mention promises to launch Foursquare check-in + Groupon rewards-type service at #SXSW. Finger's crossed. {link}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>Ha.ha. RT @mention #SXSW News: Yahoo.com is loosing search traffic to new site, Google.com. Doubt it will last tho w/ that weird name.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>Holla! RT @mention At google party. Best ever! Get your butt over here. #sxsw</td>\n",
       "      <td>Google</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>I love my @mention iPhone case from #Sxsw but I can't get my phone out of it #fail</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>I worship @mention {link} #SXSW</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>iPad2? RT @mention Droid &amp;amp; Mac here :) RT @mention My #agnerd confession, using laptop, iPad &amp;amp; blackberry to follow #SXSW</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>Launching @mention #SxSW? RT @mention @mention Denies Social Network Called Circles Will Debut Today, Despite Report {link}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>New Post: @mention iPhone app makes it easy to connect on all social networks with people you meet  {link} #sxsw</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>Nice that @mention iPhone app is behaving today. Crashes yesterday were ridiculous. #sxsw</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>Nice!  RT @mention Apple opening popup store for iPad launch in downtown Austin during #SXSW {link} via @mention</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>Nice!! RT @mention Hey, Apple fans! Get a peek at the space that's slated to be a pop-up #SXSW Apple Store tomorrow: {link}</td>\n",
       "      <td>Apple</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>one thing @mention is doing so great is get a great, down to earth face to Google as a company - You can only love her #sxsw #sxwsi</td>\n",
       "      <td>Google</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>Stay tune @mention showcase #H4ckers {link} #SXSW</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>Thank you @mention @mention for the #touchingstories preso #SXSW . Here's their deck {link}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>Thank you @mention for an awesome #sxsw party! {link}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>Thanks RT @mention If you're trying to contact friends or family in #Japan, @mention has created a person finder: {link} #SXSW</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>Thanks to @mention for her mention of our new #Speech iPad apps being showcased at the #SXSW Conf. {link} #sxswh #sxsh</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>Thanks to @mention for publishing the news of @mention new medical Apps at the #sxswi conf. blog {link} #sxsw #sxswh</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I can't tell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>Thanks to @mention for publishing the news of our new medical Apps in the #sxswi conf. blog {link} #sxsw #sxswh #mhealth</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>What !?!? @mention  #SXSW does not provide iPhone chargers?!?  I've changed my mind about going next year!</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>Wonder if @mention &amp;amp; @mention will be in the apple flashmob: tcrn.ch/fcs45j #SXSW #ipad2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>Wonder if @mention is putting tips from the @mention API... #SxSW #SUxSW</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>XMAS!! RT @mention Shiny new @mention @mention @mention apps, a new @garyvee book, pop-up iPad 2 stores... #SXSW is Christmas for nerds.</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Yai!!! RT @mention New #UberSocial for #iPhone now in the App Store includes UberGuide to #SXSW sponsored by (cont) {link}</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Yes!!! RT @mention hey @mention , i've got another gem for you --&amp;gt; free @mention sxsw {link} #SXSW</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Fast, Fun &amp;amp; Future: @mention of Google presenting at #sxsw on search, local and mobile</td>\n",
       "      <td>Google</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>GSD&amp;amp;M &amp;amp; Google's Industry Party Tonight @mention - See u there! {link} #SXSW #Austin #Welivehere #GSDM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                          Tweet  \\\n",
       "0                               .@wesley83 I have a 3G iPhone. After 3 hrs tweeting at #RISE_Austin, it was dead!  I need to upgrade. Plugin stations at #SXSW.   \n",
       "1                   @jessedee Know about @fludapp ? Awesome iPad/iPhone app that you'll likely appreciate for its design. Also, they're giving free Ts at #SXSW   \n",
       "2                                                                               @swonderlin Can not wait for #iPad 2 also. They should sale them down at #SXSW.   \n",
       "3                                                                            @sxsw I hope this year's festival isn't as crashy as this year's iPhone app. #sxsw   \n",
       "4                           @sxtxstate great stuff on Fri #SXSW: Marissa Mayer (Google), Tim O'Reilly (tech books/conferences) &amp; Matt Mullenweg (Wordpress)   \n",
       "5                  @teachntech00 New iPad Apps For #SpeechTherapy And Communication Are Showcased At The #SXSW Conference http://ht.ly/49n4M #iear #edchat #asd   \n",
       "6                                                                                                                                                           NaN   \n",
       "7                    #SXSW is just starting, #CTIA is around the corner and #googleio is only a hop skip and a jump from there, good time to be an #android fan   \n",
       "8                             Beautifully smart and simple idea RT @madebymany @thenextweb wrote about our #hollergram iPad app for #sxsw! http://bit.ly/ieaVOB   \n",
       "9                                                                      Counting down the days to #sxsw plus strong Canadian dollar means stock up on Apple gear   \n",
       "10                                       Excited to meet the @samsungmobileus at #sxsw so I can show them my Sprint Galaxy S still running Android 2.1.   #fail   \n",
       "11                            Find &amp; Start Impromptu Parties at #SXSW With @HurricaneParty http://bit.ly/gVLrIn I can't wait til the Android app comes out.   \n",
       "12                        Foursquare ups the game, just in time for #SXSW http://j.mp/grN7pK) - Still prefer @Gowalla by far, best looking Android app to date.   \n",
       "13               Gotta love this #SXSW Google Calendar featuring top parties/ show cases to check out.  RT @hamsandwich via @ischafer =&gt;http://bit.ly/aXZwxB   \n",
       "14                                                                                            Great #sxsw ipad app from @madebymany: http://tinyurl.com/4nqv92l   \n",
       "15                                                                           haha, awesomely rad iPad app by @madebymany http://bit.ly/hTdFim #hollergram #sxsw   \n",
       "16                                                                 Holler Gram for iPad on the iTunes App Store -  http://t.co/kfN3f5Q (via @marc_is_ken) #sxsw   \n",
       "17                             I just noticed DST is coming this weekend. How many iPhone users will be an hour late at SXSW come Sunday morning? #SXSW #iPhone   \n",
       "18                               Just added my #SXSW flights to @planely. Matching people on planes/airports. Also downloaded the @KLM iPhone app, nicely done.   \n",
       "19                                       Must have #SXSW app! RT @malbonster: Lovely review from Forbes for our SXSW iPad app Holler Gram - http://t.co/g4GZypV   \n",
       "20                                                   Need to buy an iPad2 while I'm in Austin at #sxsw. Not sure if I'll need to Q up at an Austin Apple store?   \n",
       "21                              Oh. My. God. The #SXSW app for iPad is pure, unadulterated awesome. It's easier to browse events on iPad than on the website!!!   \n",
       "22                                                                           Okay, this is really it: yay new @Foursquare for #Android app!!!!11 kthxbai. #sxsw   \n",
       "23                                                               Photo: Just installed the #SXSW iPhone app, which is really nice! http://tumblr.com/x6t1pi6av7   \n",
       "24             Really enjoying the changes in Gowalla 3.0 for Android! Looking forward to seeing what else they &amp; Foursquare have up their sleeves at #SXSW   \n",
       "25  RT @LaurieShook: I'm looking forward to the #SMCDallas pre #SXSW party Wed., and hoping I'll win an #iPad resulting from my shameless promotion.  #ChevySMC   \n",
       "26                                                  RT haha, awesomely rad iPad app by @madebymany http://bit.ly/hTdFim #hollergram #sxsw (via @michaelpiliero)   \n",
       "27                                                                         someone started an #austin @PartnerHub group in google groups, pre-#sxsw. great idea   \n",
       "28                  The new #4sq3 looks like it is going to rock. Update for iPhone and Android should push tonight http://bit.ly/etsbZk #SXSW #KeepAustinWeird   \n",
       "29                                                               They were right, the @gowalla 3 app on #android is sweeeeet! Nice job by the team there. #sxsw   \n",
       "30                                          Very smart from @madebymany #hollergram iPad app for #sxsw! http://t.co/A3xvWc6 (may leave my vuvuzela at home now)   \n",
       "31                       You must have this app for your iPad if you are going to #SXSW http://itunes.apple.com/us/app/holler-gram/id420666439?mt=8 #hollergram   \n",
       "32                                                          Attn: All  #SXSW frineds, @mention Register for #GDGTLive  and see Cobra iRadar for Android. {link}   \n",
       "33                                                                                                                Anyone at  #sxsw want to sell their old iPad?   \n",
       "34                                                                                Anyone at  #SXSW who bought the new iPad want to sell their older iPad to me?   \n",
       "35                                                 At #sxsw.  Oooh. RT @mention Google to Launch Major New Social Network Called Circles, Possibly Today {link}   \n",
       "36                The best!  RT @mention Ha! First in line for #ipad2 at #sxsw &quot;pop-up&quot; Apple store was an event planner #eventprofs #pcma #engage365   \n",
       "37                                        SPIN Play - a new concept in music discovery for your iPad from @mention &amp; spin.com {link} #iTunes #sxsw @mention   \n",
       "38                                      @mention  - False Alarm: Google Circles Not Coming NowÛÒand Probably Not Ever? - {link} #Google #Circles #Social #SXSW   \n",
       "39                                                                                       VatorNews - Google And Apple Force Print Media to Evolve? {link} #sxsw   \n",
       "40             @mention  - Great weather to greet you for #sxsw! Still need a sweater at night..Apple putting up &quot;flash store&quot; downtown to sell iPad2   \n",
       "41                             HootSuite - HootSuite Mobile for #SXSW ~ Updates for iPhone, BlackBerry &amp; Android: Whether youÛªre getting friend... {link}   \n",
       "42                            Hey #SXSW - How long do you think it takes us to make an iPhone case? answer @mention using #zazzlesxsw and weÛªll make you one!   \n",
       "43                                                                                   Mashable! - The iPad 2 Takes Over SXSW [VIDEO] #ipad #sxsw #gadgets {link}   \n",
       "44                                  For I-Pad ?RT @mention New #UberSocial for #iPhone now in the App Store includes UberGuide to #SXSW sponsored by ... {link}   \n",
       "45                                                 #IPad2 's Û÷#SmartCoverÛª Opens to Instant Access - I should have waited to get one! - {link} #apple #SXSW   \n",
       "46                                                                  Hand-Held Û÷HoboÛª: Drafthouse launches Û÷Hobo With a ShotgunÛª iPhone app #SXSW {link}   \n",
       "47                                                                  HOORAY RT ÛÏ@mention Apple Is Opening A Pop-Up Store In Austin For #SXSW | @mention {link}   \n",
       "48                                                                     Orly....? ÛÏ@mention Google set to launch new social network #Circles today at #sxswÛ   \n",
       "49                                                                                wooooo!!! ÛÏ@mention Apple store downtown Austin open til Midnight. #sxswÛ   \n",
       "50                Khoi Vinh (@mention says Conde Nast's headlong rush into iPad publishing was a &quot;fundamental misunderstanding&quot; of the platform #sxsw   \n",
       "51                             ÛÏ@mention {link} &lt;-- HELP ME FORWARD THIS DOC to all Anonymous accounts, techies,&amp; ppl who can help us JAM #libya #SXSW   \n",
       "52                                                                              ÷¼ WHAT? ÷_ {link} ã_ #edchat #musedchat #sxsw #sxswi #classical #newTwitter   \n",
       "53                                                                 .@mention @mention on the location-based 'fast, fun and future' - {link} (via @mention #sxsw   \n",
       "54                                        ÛÏ@mention @mention #Google Will Connect the Digital &amp; Physical Worlds Through Mobile - {link} #sxswÛ @mention   \n",
       "55                                        ÛÏ@mention @mention talking about {link} - Google's effort to allow users to have open systems #bettercloud #sxswÛ   \n",
       "56            {link} RT @mention &quot;Google before you tweet&quot; is the new &quot;think before you speak.&quot; - Mark Belinsky, #911tweets panel at #SXSW.   \n",
       "57                              {link} RT @mention 1st stop on the #SXSW #Chaos &amp; @mention hunt: Austin Java. Get in the spy game 4 a chance 2 win an iPad!   \n",
       "58                                                                   {link} RT @mention Those at #SXSW check out the Holler Gram ipad app from @mention  {link}   \n",
       "59                                                                                  @mention  @mention &amp;  @mention having fun at #google [pic] #SXSW {link}   \n",
       "60                               &quot;via @mention : {link} Guy Kawasaki talks 'Enchanted' at SXSW - HE knows his stuff! #books #internet #Apple #sxsw  &quot;   \n",
       "61                                                                   #futuremf @mention {link} spec for recipes on the web, now in google search: {link}  #sxsw   \n",
       "62                                     #OMFG! RT @mention Heard about Apple's pop-up store in downtown Austin? Pics are already on Gowalla: {link} #sxsw #iPad2   \n",
       "63            #Smile RT @mention I think Apple's &quot;pop-up store&quot; in Austin would be a lot more interesting if it actually, you know... popped up #sxsw   \n",
       "64                                                                                                 Again? RT @mention Line at the Apple store is insane.. #sxsw   \n",
       "65                Agree. RT @mention Wait. FIONA APPLE is in town??? Somebody kidnap her and put her in a recording studio until she records a new album. #sxsw   \n",
       "66                                                                     At #sxsw? @mention / @mention wanna buy you a drink. 7pm at Fado on 4th. {link} Join us!   \n",
       "67                                                                                                        attending @mention iPad design headaches #sxsw {link}   \n",
       "68                                                               Boooo! RT @mention Flipboard is developing an iPhone version, not Android, says @mention #sxsw   \n",
       "69                                           Check out @mention @mention &amp; @mention in line for their iPad 2 in Austin. Power to them! #sxswi #SXSW  {link}   \n",
       "70                                        Check! RT @mention giving added value to location based services needs to battle check-in fatigue #google #pnid #sxsw   \n",
       "71                     Chilcott: @mention #SXSW stand talking with Blogger staff. Too late to win competition for best tweet mentioning @mention So no t-shirt.   \n",
       "72                                      Do it. RT @mention Come party w/ Google tonight at #sxsw! {link} - Bands, food, art, ice cream, nifty interactive maps!   \n",
       "73                                  Gowalla's @mention promises to launch Foursquare check-in + Groupon rewards-type service at #SXSW. Finger's crossed. {link}   \n",
       "74                       Ha.ha. RT @mention #SXSW News: Yahoo.com is loosing search traffic to new site, Google.com. Doubt it will last tho w/ that weird name.   \n",
       "75                                                                                Holla! RT @mention At google party. Best ever! Get your butt over here. #sxsw   \n",
       "76                                                                           I love my @mention iPhone case from #Sxsw but I can't get my phone out of it #fail   \n",
       "77                                                                                                                              I worship @mention {link} #SXSW   \n",
       "78                            iPad2? RT @mention Droid &amp; Mac here :) RT @mention My #agnerd confession, using laptop, iPad &amp; blackberry to follow #SXSW   \n",
       "79                                  Launching @mention #SxSW? RT @mention @mention Denies Social Network Called Circles Will Debut Today, Despite Report {link}   \n",
       "80                                             New Post: @mention iPhone app makes it easy to connect on all social networks with people you meet  {link} #sxsw   \n",
       "81                                                                    Nice that @mention iPhone app is behaving today. Crashes yesterday were ridiculous. #sxsw   \n",
       "82                                             Nice!  RT @mention Apple opening popup store for iPad launch in downtown Austin during #SXSW {link} via @mention   \n",
       "83                                  Nice!! RT @mention Hey, Apple fans! Get a peek at the space that's slated to be a pop-up #SXSW Apple Store tomorrow: {link}   \n",
       "84                          one thing @mention is doing so great is get a great, down to earth face to Google as a company - You can only love her #sxsw #sxwsi   \n",
       "85                                                                                                            Stay tune @mention showcase #H4ckers {link} #SXSW   \n",
       "86                                                                  Thank you @mention @mention for the #touchingstories preso #SXSW . Here's their deck {link}   \n",
       "87                                                                                                        Thank you @mention for an awesome #sxsw party! {link}   \n",
       "88                               Thanks RT @mention If you're trying to contact friends or family in #Japan, @mention has created a person finder: {link} #SXSW   \n",
       "89                                       Thanks to @mention for her mention of our new #Speech iPad apps being showcased at the #SXSW Conf. {link} #sxswh #sxsh   \n",
       "90                                         Thanks to @mention for publishing the news of @mention new medical Apps at the #sxswi conf. blog {link} #sxsw #sxswh   \n",
       "91                                     Thanks to @mention for publishing the news of our new medical Apps in the #sxswi conf. blog {link} #sxsw #sxswh #mhealth   \n",
       "92                                                   What !?!? @mention  #SXSW does not provide iPhone chargers?!?  I've changed my mind about going next year!   \n",
       "93                                                                 Wonder if @mention &amp; @mention will be in the apple flashmob: tcrn.ch/fcs45j #SXSW #ipad2   \n",
       "94                                                                                     Wonder if @mention is putting tips from the @mention API... #SxSW #SUxSW   \n",
       "95                     XMAS!! RT @mention Shiny new @mention @mention @mention apps, a new @garyvee book, pop-up iPad 2 stores... #SXSW is Christmas for nerds.   \n",
       "96                                   Yai!!! RT @mention New #UberSocial for #iPhone now in the App Store includes UberGuide to #SXSW sponsored by (cont) {link}   \n",
       "97                                                        Yes!!! RT @mention hey @mention , i've got another gem for you --&gt; free @mention sxsw {link} #SXSW   \n",
       "98                                                                   Fast, Fun &amp; Future: @mention of Google presenting at #sxsw on search, local and mobile   \n",
       "99                                               GSD&amp;M &amp; Google's Industry Party Tonight @mention - See u there! {link} #SXSW #Austin #Welivehere #GSDM   \n",
       "\n",
       "                      Brand/Product                             Emotion  \n",
       "0                            iPhone                    Negative emotion  \n",
       "1                iPad or iPhone App                    Positive emotion  \n",
       "2                              iPad                    Positive emotion  \n",
       "3                iPad or iPhone App                    Negative emotion  \n",
       "4                            Google                    Positive emotion  \n",
       "5                               NaN  No emotion toward brand or product  \n",
       "6                               NaN  No emotion toward brand or product  \n",
       "7                           Android                    Positive emotion  \n",
       "8                iPad or iPhone App                    Positive emotion  \n",
       "9                             Apple                    Positive emotion  \n",
       "10                          Android                    Positive emotion  \n",
       "11                      Android App                    Positive emotion  \n",
       "12                      Android App                    Positive emotion  \n",
       "13  Other Google product or service                    Positive emotion  \n",
       "14               iPad or iPhone App                    Positive emotion  \n",
       "15               iPad or iPhone App                    Positive emotion  \n",
       "16                              NaN  No emotion toward brand or product  \n",
       "17                           iPhone                    Negative emotion  \n",
       "18               iPad or iPhone App                    Positive emotion  \n",
       "19               iPad or iPhone App                    Positive emotion  \n",
       "20                             iPad                    Positive emotion  \n",
       "21               iPad or iPhone App                    Positive emotion  \n",
       "22                      Android App                    Positive emotion  \n",
       "23               iPad or iPhone App                    Positive emotion  \n",
       "24                      Android App                    Positive emotion  \n",
       "25                             iPad                    Positive emotion  \n",
       "26               iPad or iPhone App                    Positive emotion  \n",
       "27  Other Google product or service                    Positive emotion  \n",
       "28               iPad or iPhone App                    Positive emotion  \n",
       "29                      Android App                    Positive emotion  \n",
       "30               iPad or iPhone App                    Positive emotion  \n",
       "31               iPad or iPhone App                    Positive emotion  \n",
       "32                              NaN  No emotion toward brand or product  \n",
       "33                              NaN  No emotion toward brand or product  \n",
       "34                              NaN  No emotion toward brand or product  \n",
       "35                              NaN  No emotion toward brand or product  \n",
       "36                             iPad                    Positive emotion  \n",
       "37                              NaN  No emotion toward brand or product  \n",
       "38                           Google                    Negative emotion  \n",
       "39                              NaN  No emotion toward brand or product  \n",
       "40                            Apple                    Positive emotion  \n",
       "41                              NaN  No emotion toward brand or product  \n",
       "42                              NaN  No emotion toward brand or product  \n",
       "43                              NaN  No emotion toward brand or product  \n",
       "44                              NaN  No emotion toward brand or product  \n",
       "45               iPad or iPhone App                    Positive emotion  \n",
       "46                              NaN                    Positive emotion  \n",
       "47                            Apple                    Positive emotion  \n",
       "48                              NaN  No emotion toward brand or product  \n",
       "49                            Apple                    Positive emotion  \n",
       "50                              NaN  No emotion toward brand or product  \n",
       "51                              NaN  No emotion toward brand or product  \n",
       "52                              NaN  No emotion toward brand or product  \n",
       "53                              NaN  No emotion toward brand or product  \n",
       "54                              NaN  No emotion toward brand or product  \n",
       "55                           Google                    Positive emotion  \n",
       "56                              NaN  No emotion toward brand or product  \n",
       "57                             iPad                    Positive emotion  \n",
       "58                              NaN  No emotion toward brand or product  \n",
       "59                              NaN  No emotion toward brand or product  \n",
       "60                              NaN  No emotion toward brand or product  \n",
       "61                              NaN  No emotion toward brand or product  \n",
       "62                            Apple                    Positive emotion  \n",
       "63                            Apple  No emotion toward brand or product  \n",
       "64                              NaN                    Negative emotion  \n",
       "65                              NaN  No emotion toward brand or product  \n",
       "66                              NaN  No emotion toward brand or product  \n",
       "67                             iPad                    Negative emotion  \n",
       "68                              NaN                    Negative emotion  \n",
       "69                             iPad                    Positive emotion  \n",
       "70                              NaN  No emotion toward brand or product  \n",
       "71                              NaN  No emotion toward brand or product  \n",
       "72                           Google                    Positive emotion  \n",
       "73                              NaN  No emotion toward brand or product  \n",
       "74                              NaN  No emotion toward brand or product  \n",
       "75                           Google                    Positive emotion  \n",
       "76                           iPhone                    Positive emotion  \n",
       "77                              NaN  No emotion toward brand or product  \n",
       "78                              NaN  No emotion toward brand or product  \n",
       "79                              NaN  No emotion toward brand or product  \n",
       "80               iPad or iPhone App                    Positive emotion  \n",
       "81               iPad or iPhone App                    Positive emotion  \n",
       "82                              NaN  No emotion toward brand or product  \n",
       "83                            Apple                    Positive emotion  \n",
       "84                           Google                    Positive emotion  \n",
       "85                              NaN  No emotion toward brand or product  \n",
       "86                              NaN  No emotion toward brand or product  \n",
       "87                              NaN  No emotion toward brand or product  \n",
       "88                              NaN  No emotion toward brand or product  \n",
       "89               iPad or iPhone App                    Positive emotion  \n",
       "90                              NaN                        I can't tell  \n",
       "91                              NaN  No emotion toward brand or product  \n",
       "92                           iPhone                    Negative emotion  \n",
       "93                              NaN  No emotion toward brand or product  \n",
       "94                              NaN  No emotion toward brand or product  \n",
       "95                             iPad                    Positive emotion  \n",
       "96                           iPhone                    Positive emotion  \n",
       "97                              NaN  No emotion toward brand or product  \n",
       "98                           Google                    Positive emotion  \n",
       "99                              NaN  No emotion toward brand or product  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My dataset has more than 9000 tweets and is split in 3 columns. The first column is the tweet, the second one is the information if the tweet is directed at a specific product (Apple or Google) and the third one is the sentiment towards the product.\n",
    "The second column only contains 3200 data points so we don't know about every of the 9000 tweets at which product they are directed at. Also the 3rd column shows for the majority of tweets no emotion. \n",
    "My next steps are to summarize the different products into the two brands Apple or Google and to check if the missing values in the product column really don't include any information about a product."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Cleaning of the Brand/Product column\n",
    "First, I will rename the different products and map them to the brand Apple or Google."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "iPad                               946\n",
       "Apple                              661\n",
       "iPad or iPhone App                 470\n",
       "Google                             430\n",
       "iPhone                             297\n",
       "Other Google product or service    293\n",
       "Android App                         81\n",
       "Android                             78\n",
       "Other Apple product or service      35\n",
       "Name: Brand/Product, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#identify distribution of column\n",
    "df[\"Brand/Product\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple     2409\n",
      "Google     882\n",
      "Name: Brand, dtype: int64\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9093 entries, 0 to 9092\n",
      "Data columns (total 4 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   Tweet          9092 non-null   object\n",
      " 1   Brand/Product  3291 non-null   object\n",
      " 2   Emotion        9093 non-null   object\n",
      " 3   Brand          3291 non-null   object\n",
      "dtypes: object(4)\n",
      "memory usage: 284.3+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#map product category to brand\n",
    "product_mapping = {\n",
    "    \"iPad\": \"Apple\",\n",
    "    \"iPad or iPhone App\": \"Apple\",\n",
    "    \"iPhone\": \"Apple\",\n",
    "    \"Other Apple product or service\": \"Apple\",\n",
    "    \"Other Google product or service\": \"Google\",\n",
    "    \"Android App\": \"Google\",\n",
    "    \"Android\": \"Google\"\n",
    "}\n",
    "\n",
    "\n",
    "df[\"Brand\"] = df[\"Brand/Product\"].replace(product_mapping)\n",
    "print(df[\"Brand\"].value_counts())\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.1 Populate missing brand column\n",
    "Now, where this is cleaned up, I will look at the na values to see if there are no information connected to Apple or Google."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5           @teachntech00 New iPad Apps For #SpeechTherapy And Communication Are Showcased At The #SXSW Conference http://ht.ly/49n4M #iear #edchat #asd\n",
       "6                                                                                                                                                    NaN\n",
       "16                                                          Holler Gram for iPad on the iTunes App Store -  http://t.co/kfN3f5Q (via @marc_is_ken) #sxsw\n",
       "32                                                   Attn: All  #SXSW frineds, @mention Register for #GDGTLive  and see Cobra iRadar for Android. {link}\n",
       "33                                                                                                         Anyone at  #sxsw want to sell their old iPad?\n",
       "34                                                                         Anyone at  #SXSW who bought the new iPad want to sell their older iPad to me?\n",
       "35                                          At #sxsw.  Oooh. RT @mention Google to Launch Major New Social Network Called Circles, Possibly Today {link}\n",
       "37                                 SPIN Play - a new concept in music discovery for your iPad from @mention &amp; spin.com {link} #iTunes #sxsw @mention\n",
       "39                                                                                VatorNews - Google And Apple Force Print Media to Evolve? {link} #sxsw\n",
       "41                      HootSuite - HootSuite Mobile for #SXSW ~ Updates for iPhone, BlackBerry &amp; Android: Whether youÛªre getting friend... {link}\n",
       "42                     Hey #SXSW - How long do you think it takes us to make an iPhone case? answer @mention using #zazzlesxsw and weÛªll make you one!\n",
       "43                                                                            Mashable! - The iPad 2 Takes Over SXSW [VIDEO] #ipad #sxsw #gadgets {link}\n",
       "44                           For I-Pad ?RT @mention New #UberSocial for #iPhone now in the App Store includes UberGuide to #SXSW sponsored by ... {link}\n",
       "46                                                           Hand-Held Û÷HoboÛª: Drafthouse launches Û÷Hobo With a ShotgunÛª iPhone app #SXSW {link}\n",
       "48                                                              Orly....? ÛÏ@mention Google set to launch new social network #Circles today at #sxswÛ\n",
       "50         Khoi Vinh (@mention says Conde Nast's headlong rush into iPad publishing was a &quot;fundamental misunderstanding&quot; of the platform #sxsw\n",
       "51                      ÛÏ@mention {link} &lt;-- HELP ME FORWARD THIS DOC to all Anonymous accounts, techies,&amp; ppl who can help us JAM #libya #SXSW\n",
       "52                                                                       ÷¼ WHAT? ÷_ {link} ã_ #edchat #musedchat #sxsw #sxswi #classical #newTwitter\n",
       "53                                                          .@mention @mention on the location-based 'fast, fun and future' - {link} (via @mention #sxsw\n",
       "54                                 ÛÏ@mention @mention #Google Will Connect the Digital &amp; Physical Worlds Through Mobile - {link} #sxswÛ @mention\n",
       "56     {link} RT @mention &quot;Google before you tweet&quot; is the new &quot;think before you speak.&quot; - Mark Belinsky, #911tweets panel at #SXSW.\n",
       "58                                                            {link} RT @mention Those at #SXSW check out the Holler Gram ipad app from @mention  {link}\n",
       "59                                                                           @mention  @mention &amp;  @mention having fun at #google [pic] #SXSW {link}\n",
       "60                        &quot;via @mention : {link} Guy Kawasaki talks 'Enchanted' at SXSW - HE knows his stuff! #books #internet #Apple #sxsw  &quot;\n",
       "61                                                            #futuremf @mention {link} spec for recipes on the web, now in google search: {link}  #sxsw\n",
       "64                                                                                          Again? RT @mention Line at the Apple store is insane.. #sxsw\n",
       "65         Agree. RT @mention Wait. FIONA APPLE is in town??? Somebody kidnap her and put her in a recording studio until she records a new album. #sxsw\n",
       "66                                                              At #sxsw? @mention / @mention wanna buy you a drink. 7pm at Fado on 4th. {link} Join us!\n",
       "68                                                        Boooo! RT @mention Flipboard is developing an iPhone version, not Android, says @mention #sxsw\n",
       "70                                 Check! RT @mention giving added value to location based services needs to battle check-in fatigue #google #pnid #sxsw\n",
       "71              Chilcott: @mention #SXSW stand talking with Blogger staff. Too late to win competition for best tweet mentioning @mention So no t-shirt.\n",
       "73                           Gowalla's @mention promises to launch Foursquare check-in + Groupon rewards-type service at #SXSW. Finger's crossed. {link}\n",
       "74                Ha.ha. RT @mention #SXSW News: Yahoo.com is loosing search traffic to new site, Google.com. Doubt it will last tho w/ that weird name.\n",
       "77                                                                                                                       I worship @mention {link} #SXSW\n",
       "78                     iPad2? RT @mention Droid &amp; Mac here :) RT @mention My #agnerd confession, using laptop, iPad &amp; blackberry to follow #SXSW\n",
       "79                           Launching @mention #SxSW? RT @mention @mention Denies Social Network Called Circles Will Debut Today, Despite Report {link}\n",
       "82                                      Nice!  RT @mention Apple opening popup store for iPad launch in downtown Austin during #SXSW {link} via @mention\n",
       "85                                                                                                     Stay tune @mention showcase #H4ckers {link} #SXSW\n",
       "86                                                           Thank you @mention @mention for the #touchingstories preso #SXSW . Here's their deck {link}\n",
       "87                                                                                                 Thank you @mention for an awesome #sxsw party! {link}\n",
       "88                        Thanks RT @mention If you're trying to contact friends or family in #Japan, @mention has created a person finder: {link} #SXSW\n",
       "90                                  Thanks to @mention for publishing the news of @mention new medical Apps at the #sxswi conf. blog {link} #sxsw #sxswh\n",
       "91                              Thanks to @mention for publishing the news of our new medical Apps in the #sxswi conf. blog {link} #sxsw #sxswh #mhealth\n",
       "93                                                          Wonder if @mention &amp; @mention will be in the apple flashmob: tcrn.ch/fcs45j #SXSW #ipad2\n",
       "94                                                                              Wonder if @mention is putting tips from the @mention API... #SxSW #SUxSW\n",
       "97                                                 Yes!!! RT @mention hey @mention , i've got another gem for you --&gt; free @mention sxsw {link} #SXSW\n",
       "99                                        GSD&amp;M &amp; Google's Industry Party Tonight @mention - See u there! {link} #SXSW #Austin #Welivehere #GSDM\n",
       "100                     New buzz? &quot;@mention Google to Launch Major New Social Network Called Circles, Possibly Today {link} rt @mention #sxsw&quot;\n",
       "102                      ÛÏ@mention &quot;Apple has opened a pop-up store in Austin so the nerds in town for #SXSW can get their new iPads. {link} #wow\n",
       "103                                                 Know that &quot;dataviz&quot; translates to &quot;satanic&quot; on an iPhone. I'm just sayin'. #sxsw\n",
       "105              .@mention &quot;Google launched checkins a month ago.&quot; Check ins are ok, but CHECK OUTS are the future. #sxsw #Bizzy (via @mention\n",
       "107      Attending &quot;left brain search = Google, Right brain search = X&quot;  #Bettersearch  -- talking about the future of search engines at #sxsw\n",
       "108                   #HP opens &quot;Mobile Park&quot;  &amp; Content Incubator at #SXSW  {link}   #Apple  constructs  &quot;pop-up&quot; store  {link}\n",
       "110                                                      Kawasaki: &quot;pagemaker saved Apple.&quot; Oh those were the days. #sxsw #jwtatl #enchantment\n",
       "112                                                                Spark for #android is up for a #teamandroid award at #SXSW read about it here: {link}\n",
       "113                                                                                            Unboxing. #Apple #sxsw  @mention Apple Store, SXSW {link}\n",
       "115                                                                           At #SXSW, #Apple schools the #marketing experts | SXSW - CNET Blogs {link}\n",
       "117                                                                                                At #SXSW, #Apple schools the marketing experts {link}\n",
       "122                                        Headed to #Austin for #SXSW? Check out my map for newbies {link} @mention @mention , @mention @mention Enjoy!\n",
       "123                      Funny how #Austin is trending but not #SXSW. Only a matter of minutes at this point (at least according to Twitter for iPhone).\n",
       "125           #sxsw #ux #ipad #uxdes remember to ultimately be aware of the audience your app is targeted towards. An unexpected experience can be good.\n",
       "129                                              #Google's #Mobile Future, and the Elusive 'Power of Here' - {link} (via @mention #eurorscg #sxsw #sxswi\n",
       "130                                                              For those #notatSXSW (or at #SXSW), here's {link} Free to download and meet nearby peps\n",
       "131                                               Does your #SmallBiz need reviews to play on Google Places...We got an App for that..{link}  #seo #sxsw\n",
       "132                                                Does your #SmallBiz need reviews to play on Google Places...We got an App for that..{link} #seo #sxsw\n",
       "133                                                                           #Samsung, #Sony follow #Apple, #HP lead @mention {link} #Austin #atx #SXSW\n",
       "134                                                         #Samsung, #Sony follow #Apple, #HP lead @mention {link} #Austin #atx #SXSW /via @mention ^rg\n",
       "137             Q1 Was at #sxsw #sxswi for prep. Amazing pre push locally. Focus on location based. Google owns 10% of the regions billboards. #pr20chat\n",
       "138                                                                            Any other #Sxsw accounts I need to follow or apps to download for iPhone?\n",
       "139                                 Headed to #sxsw and want to share/gather contact info? {link} can turn your iphone into a business card broadcaster.\n",
       "140                                                  Headed to #sxsw and want to share/gather contact info? {link} can turn your iphone into a... {link}\n",
       "141                                                                       BTW - The #sxsw Apple store is sold out of all 3G models (VZW &amp; AT&amp;T).\n",
       "144                                                     Anyone at #sxsw been by the pop-up Apple store in Austin? That's gotta be a hopping place today.\n",
       "147       #fastball #sxsw Giving away two NEW Ipad2 wifi 32g black Apple cover tweet @mention fo more info #sxswi #attsxsw  Tonight @mention bo.lt house\n",
       "148                    Anyone at #sxsw had a chance to check out the pop-up Apple store? Wondering if it is worth the trek from the convention center...\n",
       "152                                                  @mention  #SXSW is an Austin conference. Do a google search - they have interactive / music / film.\n",
       "153                                                                                  Anyone at #sxsw know if apple will be (or is) selling ipad 2 there?\n",
       "154                                                                         Anyone at #SXSW know if the apple store has had a new shipment of iPads yet?\n",
       "155                                  Marc Ecko #SXSW launches #iPhone app. to autodial political change! {link} #edreform #edtech #eduVC #FightThePaddle\n",
       "157                                                  @mention  #SXSW LonelyPlanet Austin guide for #iPhone is free for a limited time {link} #lp #travel\n",
       "158                                                                                         More free #SXSW mp3 downloads, this time from iTunes: {link}\n",
       "159                                                                    Anyone at #sxsw or heading to aclu event seen owt to do with google circles then?\n",
       "160                                                                    @mention  #SXSW prompt for memory: go to Google map and describe a childhood walk\n",
       "162                                                                                                                        Essential #sxsw tools: {link}\n",
       "164           Following #sxsw Tweets on Google Realtime, four platforms on Tweet Deck and listening to panel, realizing I'm spoken to no one here today.\n",
       "165                          Anyone at #sxsw want an iPad 2? I'm in line and will pick one up for someone willing to pay me 50 for me to grab 1 for you?\n",
       "167                                                Solving a #SXSW-induced iPhone-in-toilet crisis at Apple Store with @mention (not my crisis for once)\n",
       "169                                                             Attending #sxsw? Austin Guide by @mention is now free to download on iTunes - {link} #lp\n",
       "175                                                        Hey #sxsw #sxswi folks. If you want to learn about security come over to #bsidesaustin {link}\n",
       "176             Attending #SXSWi? Work in iPhone / iPad game development? Looking to hire an Austin-based iOS developer? I'm your man. Let's talk. #SXSW\n",
       "178                                                   GSD&amp;M + Google 7-10. RT @mention What's the best party to hit tonight? #sxsw @mention @mention\n",
       "179                                                                           GSD&amp;M + Google Industry Party #SXSW @mention great to meet you  {link}\n",
       "181                                             #sxsw day 1 - Marissa Mayer: Google Will Connect the Digital &amp; Physical Worlds Through Mobile {link}\n",
       "184                                                                                       .@mention 1154 free songs from #SXSW (this year alone!) {link}\n",
       "185                                                                                  more than 150 million mobile users for Google Maps for Mobile #SXSW\n",
       "186                                                                             Currently 150 people in line at the &quot;Pop Up Apple Store&quot; #sxsw\n",
       "187                              Only iPad 2 available at #sxsw is the 64GB wifi-only model at $699, plus the optional (not!) leather smart cover at $69\n",
       "188                      ÷¼ We love 2 entertain youÛ_Please donÛªt be grateful! ÷_ {link} ã_ #edchat #musedchat #sxsw #sxswi #classical #newTwitter\n",
       "189                                                                 Less than 2 hours until we announce the details on the iPad 2 giveaway! #SXSW #SXSWi\n",
       "191                                                                                                                 (The iPad 2 queue at #sxsw of course\n",
       "Name: Tweet, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df = df[df['Brand'].isna()]\n",
    "\n",
    "# Select the first 100 lines of column A from the filtered DataFrame\n",
    "column_a_subset = filtered_df['Tweet']\n",
    "column_a_subset[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like there are indeed words in the tweets that will let us identify the brand from the comment. I will create a list of keywords and map them to the different brands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign rows to Brand/Product for the unknown one\n",
    "\n",
    "keywords = ['google', 'apple', 'ipad', 'android', 'iphone']\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    text = row['Tweet']\n",
    "    if pd.isna(row['Brand/Product']) and isinstance(text, str):\n",
    "        for keyword in keywords:\n",
    "            if keyword in text.lower():\n",
    "                df.at[index, 'Brand/Product'] = keyword\n",
    "                break\n",
    "# fill the rest with Unknown\n",
    "df['Brand/Product'] = df['Brand/Product'].fillna('Unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "brand_keywords = {\n",
    "    \"Apple\": [\"ipad\", \"iphone\", \"itunes\", \"apple\"],\n",
    "    \"Google\": [\"android\", \"google\"]\n",
    "}\n",
    "\n",
    "# Iterate over the DataFrame and update the 'Brand' column for tweets with missing brand information\n",
    "for index, row in df.iterrows():\n",
    "    if pd.isna(row['Brand']):  # Check if the brand is NaN\n",
    "        tweet = row['Tweet']\n",
    "        if isinstance(tweet, str):  # Check if the tweet is a string\n",
    "            tweet = tweet.lower()  # Transform the tweet to lowercase\n",
    "            for brand, keywords in brand_keywords.items():\n",
    "                for keyword in keywords:\n",
    "                    if keyword in tweet:\n",
    "                        df.at[index, 'Brand'] = brand\n",
    "                        break  # Break the loop if a matching keyword is found\n",
    "        else:\n",
    "            df.at[index, 'Brand'] = 'unknown'  # Assign 'unknown' for NaN values in 'Brand' column\n",
    "\n",
    "# Assign 'unknown' for any remaining NaN values in 'Brand' column\n",
    "df['Brand'].fillna('unknown', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Apple      5401\n",
       "Google     2985\n",
       "unknown     707\n",
       "Name: Brand, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Brand\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since I want to advise Google and Apple about their products, I will drop the rows where we don't have the brand or product information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df[\"Brand\"] != \"unknown\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.2 Clean up Brand/Product column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "google                             1740\n",
       "apple                              1195\n",
       "ipad                               1069\n",
       "iPad                                946\n",
       "iphone                              710\n",
       "Apple                               661\n",
       "iPad or iPhone App                  470\n",
       "Google                              430\n",
       "android                             326\n",
       "iPhone                              297\n",
       "Other Google product or service     293\n",
       "Android App                          81\n",
       "Android                              78\n",
       "Unknown                              55\n",
       "Other Apple product or service       35\n",
       "Name: Brand/Product, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Brand/Product\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to do a bit of clean up because of lower case and upper case values. I will map the different categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Google                             2170\n",
      "iPad                               2015\n",
      "Apple                              1856\n",
      "iPhone                             1007\n",
      "iPad or iPhone App                  470\n",
      "Android                             404\n",
      "Other Google product or service     293\n",
      "Android App                          81\n",
      "Unknown                              55\n",
      "Other Apple product or service       35\n",
      "Name: Brand/Product, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "product_mapping = {\n",
    "    \"google\": \"Google\",\n",
    "    \"apple\": \"Apple\",\n",
    "    \"ipad\": \"iPad\",\n",
    "    \"iphone\": \"iPhone\",\n",
    "    \"android\": \"Android\"\n",
    "}\n",
    "df[\"Brand/Product\"] = df[\"Brand/Product\"].replace(product_mapping)\n",
    "print(df[\"Brand/Product\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.3 Drop duplicates and missing values\n",
    "Also, I want to check for duplicates or missing values and remove them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before removal:  False    8366\n",
      "True       20\n",
      "dtype: int64\n",
      "After removal:  False    8366\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Before removal: \", df.duplicated().value_counts())\n",
    "df.drop_duplicates(inplace=True)\n",
    "print(\"After removal: \",df.duplicated().value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 8366 entries, 0 to 9092\n",
      "Data columns (total 4 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   Tweet          8366 non-null   object\n",
      " 1   Brand/Product  8366 non-null   object\n",
      " 2   Emotion        8366 non-null   object\n",
      " 3   Brand          8366 non-null   object\n",
      "dtypes: object(4)\n",
      "memory usage: 326.8+ KB\n"
     ]
    }
   ],
   "source": [
    "#check for missing values\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.4 Clean up Emotion column\n",
    "Next, I want to clean up the Emotion column. There are 4 different options: Positive emotion, negative emotion, no emotion and can't tell. The \"no emotion\" option is the most common one and since I want to create a binary classifier, I will leave positive as positive and combine the neutral and negative ones as non-positive. Also,  I will  drop the can't tell rows as they are only a very small fraction of the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No emotion toward brand or product    4688\n",
       "Positive emotion                      2960\n",
       "Negative emotion                       568\n",
       "I can't tell                           150\n",
       "Name: Emotion, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Emotion\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Non-positive    0.639727\n",
       "Positive        0.360273\n",
       "Name: Emotion, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#emotions dictionary for mapping\n",
    "emotions = {\n",
    "    \"No emotion toward brand or product\": \"Non-positive\",\n",
    "    \"Positive emotion\": \"Positive\",\n",
    "    \"Negative emotion\": \"Non-positive\"\n",
    "}\n",
    "#mapping old labels to new ones\n",
    "df[\"Emotion\"] = df[\"Emotion\"].map(emotions)\n",
    "#check for nas and drop them (can't tell)\n",
    "print(df['Emotion'].isnull().sum())\n",
    "# Drop NaN in the emotion column\n",
    "df.dropna(subset = [\"Emotion\"], inplace = True)\n",
    "#check for distribution\n",
    "df[\"Emotion\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#changing to numerical\n",
    "df[\"Emotion\"] = df[\"Emotion\"].map({'Non-positive': 0, 'Positive': 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For my future target variable, I can note that I have a class imbalance. 64% of the cases are not positive, so I will perform different oversampling or undersampling techniques after the train test split to avoid data leakage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Exploratory Data Analysis\n",
    "Before I start with splitting my dataset and doing the preprocessing, I want to get more familiar with the most frequent words.  In this section, I will see how my tokens look like so that I can remove certain stop words in my model.\n",
    "\n",
    "### 4.1 Basic preprocessing\n",
    "\n",
    "Now that I have my dataframe cleaned up, I will start with preparing the tweet texts. Here are the decisions, I have taken:\n",
    "\n",
    "Stop word removal: I will remove some basic stop words\n",
    "\n",
    "Tokenization: I will use a specific Tweet Tokenizer that handles hashtags and mentions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1.1: Tokenization using TweetTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('#sxsw', 8219), ('.', 5525), ('the', 4043), ('link', 3613), ('}', 3599), ('{', 3596), (',', 3261), ('to', 3244), ('at', 2816), ('rt', 2654), ('ipad', 2367), ('for', 2309), ('a', 2164), ('!', 2125), ('google', 2082), ('in', 1780), ('apple', 1778), ('is', 1593), ('of', 1560), ('\"', 1553)]\n"
     ]
    }
   ],
   "source": [
    "#initialising Tokenizer \n",
    "tknzr = TweetTokenizer(strip_handles=True, preserve_case=False)\n",
    "df['Tokens'] = df['Tweet'].apply(tknzr.tokenize)\n",
    "\n",
    "#writing a function to get the 20 most common words\n",
    "def get_most_common_words(df, column_name, N=20):\n",
    "    # Flatten the list of tokens into a single list\n",
    "    all_tokens = [token for tokens in df[column_name] for token in tokens]\n",
    "\n",
    "    # Calculate the frequency distribution\n",
    "    freq_dist = FreqDist(all_tokens)\n",
    "\n",
    "    # Get the top N common words\n",
    "    most_common_words = freq_dist.most_common(N)\n",
    "\n",
    "    return most_common_words\n",
    "\n",
    "# applying the function\n",
    "top_words = get_most_common_words(df, 'Tokens', N=20)\n",
    "print(top_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the list of most common words, there are a lot of common words / stopwords included that I will get rid of. Also, I will include \"sxsw\" which is an acronym for the Southwest Bank and \"rt\" which probably stands for retweet to my list of stopwords.I will first remove the stopwords and then see what else I can remove."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1.2: Removing stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('.', 5525), ('link', 3613), ('}', 3599), ('{', 3596), (',', 3261), ('ipad', 2367), ('!', 2125), ('google', 2082), ('apple', 1778), ('\"', 1553), (':', 1485), ('store', 1440), ('?', 1436), ('2', 1289), ('iphone', 1278), ('-', 1072), ('new', 1035), ('austin', 776), ('app', 753), ('&', 738)]\n"
     ]
    }
   ],
   "source": [
    "# Get the set of English stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "additional_stopwords = [\"#sxsw\", \"sxsw\", \"sxswi\", \"#sxswi\", \"rt\"]\n",
    "stop_words.update(additional_stopwords)\n",
    "\n",
    "# Function to remove stopwords from a list of tokens\n",
    "def remove_stopwords(tokens):\n",
    "    return [token for token in tokens if token not in stop_words]\n",
    "\n",
    "# Apply the remove_stopwords function to the 'tokens' column\n",
    "df['Tokens'] = df['Tokens'].apply(remove_stopwords)\n",
    "#get the top 20 words\n",
    "top_words = get_most_common_words(df, 'Tokens', N=20)\n",
    "print(top_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will also remove the product specific words and treat them as stopwords. I have this information already in my brand and product column, so I know which Apple or Google product the tweet is about. Also, I will remove punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('new', 1035), ('app', 753), ('launch', 608), ('social', 597), ('circles', 539), ('today', 516), ('network', 440), ('pop-up', 410), ('via', 397), ('line', 392), ('get', 365), ('called', 337), ('party', 303), ('mobile', 298), ('major', 290), ('free', 274), ('like', 269), ('temporary', 261), ('one', 260), ('time', 257)]\n"
     ]
    }
   ],
   "source": [
    "additional_stopwords = [\n",
    "    \"ipad\", \"google\", \"apple\", \"iphone\", \"amp\",\n",
    "    \"android\", \"sxswi\", \"link\", \"#apple\",\n",
    "    \"#google\", \"...\", \"\\x89\", \"#ipad2\",\n",
    "    \"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\n",
    "    \"#iphone\", \"#android\", \"store\", \"austin\", \"#ipad\"]\n",
    "stop_words.update(additional_stopwords)\n",
    "\n",
    "# Apply the remove_stopwords function to the 'tokens' column\n",
    "df['Tokens'] = df['Tokens'].apply(remove_stopwords)\n",
    "# Remove punctuation from the tokens\n",
    "df['Tokens'] = df['Tokens'].apply(lambda tokens: [token for token in tokens if token not in string.punctuation])\n",
    "#get most common words\n",
    "top_words = get_most_common_words(df, 'Tokens', N=20)\n",
    "print(top_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1.3: Check most common words for Apple and Google products\n",
    "To understand the most common words a bit better in order to decide if I need to exclude anything else in the stopwords, I will check for both Google and Apple products the most common words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting up data in brands and emotions\n",
    "apple = df[df[\"Brand\"]==\"Apple\"]\n",
    "apple_pos = apple[apple[\"Emotion\"]==1]\n",
    "apple_nonpos = apple[apple[\"Emotion\"]==0]\n",
    "google = df[df[\"Brand\"]==\"Google\"]\n",
    "google_pos = google[google[\"Emotion\"]==1]\n",
    "google_nonpos = google[google[\"Emotion\"]==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('app', 309), ('new', 219), ('pop-up', 151), ('line', 123), ('get', 120), ('via', 103), ('one', 98), (\"i'm\", 96), ('cool', 96), ('temporary', 89), ('free', 88), ('opening', 87), ('downtown', 86), ('like', 81), ('go', 79), ('launch', 78), ('time', 78), ('great', 77), ('popup', 76), ('day', 73)]\n"
     ]
    }
   ],
   "source": [
    "top_words = get_most_common_words(apple_pos, \"Tokens\", N=20)\n",
    "print(top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('app', 286), ('pop-up', 259), ('new', 257), ('line', 250), ('temporary', 172), ('opening', 166), ('get', 147), ('via', 137), ('free', 131), ('downtown', 130), ('popup', 129), ('open', 129), ('one', 121), ('launch', 118), ('pop', 102), ('like', 99), ('need', 96), (\"i'm\", 95), ('win', 93), ('people', 92)]\n"
     ]
    }
   ],
   "source": [
    "top_words = get_most_common_words(apple_nonpos, \"Tokens\", N=20)\n",
    "print(top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('new', 139), ('party', 105), ('circles', 105), ('social', 103), ('maps', 101), ('network', 84), ('launch', 81), ('mobile', 73), ('app', 72), ('mayer', 64), ('today', 63), ('called', 60), ('great', 59), ('marissa', 59), (\"google's\", 56), ('major', 54), ('time', 49), ('w', 41), ('possibly', 41), ('get', 38)]\n"
     ]
    }
   ],
   "source": [
    "top_words = get_most_common_words(google_pos, \"Tokens\", N=20)\n",
    "print(top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('social', 439), ('circles', 433), ('new', 420), ('network', 345), ('launch', 331), ('today', 316), ('called', 262), ('major', 228), ('possibly', 187), ('mobile', 166), ('party', 140), ('via', 128), ('mayer', 124), (\"google's\", 121), ('marissa', 117), ('maps', 106), ('app', 86), ('#circles', 79), ('search', 77), ('bing', 69)]\n"
     ]
    }
   ],
   "source": [
    "top_words = get_most_common_words(google_nonpos, \"Tokens\", N=20)\n",
    "print(top_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model building\n",
    "My steps for modeling are the following:\n",
    "1. Removing stop-words \n",
    "2. Train-Test-Split\n",
    "3. Address class imbalance\n",
    "4. Build and train baseline model with basic preprocessing and a vectorizer\n",
    "5. Evaluate the baseline model\n",
    "6. Finetune the preprocessing\n",
    "7. Potentially include other features\n",
    "8. Iterate through different models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1: Removing stopwords\n",
    "Based on my EDA, I will remove a specific list of stopwords that has to do with the sxsw festival and product related words that won't have a lot of value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write function to remove stopwords\n",
    "def remove_stopwords(tweet):\n",
    "    stop_words = set(stopwords.words('english')) #basic stopwords\n",
    "    additional_stopwords = [\n",
    "        \"#sxsw\", \"sxsw\", \"sxswi\", \"#sxswi\", \"rt\",\"ipad\",\n",
    "        \"google\", \"apple\", \"iphone\", \"amp\",\n",
    "        \"android\", \"sxswi\", \"link\", \"#apple\",\n",
    "        \"#google\", \"...\", \"\\x89\", \"#ipad2\",\n",
    "        \"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\n",
    "        \"#iphone\", \"#android\", \"store\", \"austin\", \"#ipad\"\n",
    "    ] + list(string.punctuation) \n",
    "    stop_words.update(additional_stopwords)\n",
    "    \n",
    "    filtered_tweet = ' '.join([word for word in tweet.split() if word.lower() not in stop_words])\n",
    "    return filtered_tweet\n",
    "# add column with filtered tweets\n",
    "df[\"Tweets_filtered\"] = df[\"Tweet\"].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2: Train-Test-Split\n",
    "To avoid data leakage, I will now split my cleaned dataset into train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (6162, 1) (6162,)\n",
      "Testing data shape: (2054, 1) (2054,)\n",
      "Training data shape: (6162,) (6162,)\n",
      "Testing data shape: (2054,) (2054,)\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "X = df[['Tweets_filtered']]  # Feature\n",
    "y = df['Emotion']  # Target variable\n",
    "\n",
    "# Split the data into 75% training and 25% testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Print the shapes of the resulting datasets\n",
    "print(\"Training data shape:\", X_train.shape, y_train.shape)\n",
    "print(\"Testing data shape:\", X_test.shape, y_test.shape)\n",
    "# Reshape X_train and X_test\n",
    "X_train = X_train.values.ravel()\n",
    "X_test = X_test.squeeze()\n",
    "# Print the updated shapes\n",
    "print(\"Training data shape:\", X_train.shape, y_train.shape)\n",
    "print(\"Testing data shape:\", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3: Building a baseline model - logistic regression, oversampling , count vectorization\n",
    "I will now build a logistic regression model with random oversampling and Count vectorization but without applying a specific tokenizer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vectorizer', CountVectorizer()),\n",
       "                ('oversample', RandomOverSampler(random_state=42)),\n",
       "                ('classifier', LogisticRegression())])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define pipeline\n",
    "pipe_lr = Pipeline([\n",
    "    ('vectorizer', CountVectorizer()),\n",
    "    ('oversample', RandomOverSampler(random_state=42)),\n",
    "    ('classifier', LogisticRegression())\n",
    "])\n",
    "\n",
    "# Fit the pipeline on the resampled training data\n",
    "pipe_lr.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.70\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.77      0.77      1326\n",
      "           1       0.58      0.58      0.58       728\n",
      "\n",
      "    accuracy                           0.70      2054\n",
      "   macro avg       0.67      0.67      0.67      2054\n",
      "weighted avg       0.70      0.70      0.70      2054\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predict on the test data\n",
    "y_pred = pipe_lr.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(\"Classification Report:\\n\", report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classification report of the linear regression model indicates moderate performance. The weighted average for precision, recall and f1-score is 0.7. The overall accuracy of the model was 0.7. \n",
    "\n",
    "### 5.4 Model iteration - logistic regression, oversample, count vectorizer, TweetTokenizer\n",
    "\n",
    "Next, I will try the same model but with TweetTokenizer. Based on my EDA, I will do tokenization by using TweetTokenizer that handles hashtags and mentions and apply lemmatization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vectorizer',\n",
       "                 CountVectorizer(tokenizer=<function custom_tokenizer at 0x000002AC0B120310>)),\n",
       "                ('oversample', RandomOverSampler(random_state=42)),\n",
       "                ('lr', LogisticRegression(max_iter=1000, random_state=42))])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate lemmatizer and tokenizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "tokenizer = TweetTokenizer()\n",
    "# Define a custom tokenizer function that applies lemmatization\n",
    "def custom_tokenizer(text):\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    return lemmatized_tokens\n",
    "\n",
    "# Instantiate tweet tokenizer to later include in the pipeline\n",
    "lr_pipe_tknzr = Pipeline([\n",
    "    ('vectorizer', CountVectorizer(tokenizer=custom_tokenizer)),\n",
    "    ('oversample', RandomOverSampler(random_state=42)),\n",
    "    ('lr', LogisticRegression(random_state=42, max_iter=1000))\n",
    "])\n",
    "\n",
    "lr_pipe_tknzr.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.71\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.77      0.77      1326\n",
      "           1       0.59      0.59      0.59       728\n",
      "\n",
      "    accuracy                           0.71      2054\n",
      "   macro avg       0.68      0.68      0.68      2054\n",
      "weighted avg       0.71      0.71      0.71      2054\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predict on the test data\n",
    "y_pred = lr_pipe_tknzr.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(\"Classification Report:\\n\", report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This slightly improved the model. I will try a different vectorization (TFIDF) to see if that improves the model\n",
    "\n",
    "### 5.5 Model iteration - Logistic regression, oversample, TFIDF vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vectorizer',\n",
       "                 TfidfVectorizer(tokenizer=<function custom_tokenizer at 0x000002AC0B120310>)),\n",
       "                ('oversample', RandomOverSampler(random_state=42)),\n",
       "                ('lr', LogisticRegression(random_state=42))])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_pipe_tknzr_oversample = Pipeline([\n",
    "    ('vectorizer', TfidfVectorizer(tokenizer=custom_tokenizer)),\n",
    "    ('oversample', RandomOverSampler(random_state=42)),\n",
    "    ('lr', LogisticRegression(random_state=42))\n",
    "])\n",
    "\n",
    "lr_pipe_tknzr_oversample.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.71\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.76      0.77      1326\n",
      "           1       0.58      0.62      0.60       728\n",
      "\n",
      "    accuracy                           0.71      2054\n",
      "   macro avg       0.68      0.69      0.69      2054\n",
      "weighted avg       0.71      0.71      0.71      2054\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predict on the test data\n",
    "y_pred = lr_pipe_tknzr_oversample.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(\"Classification Report:\\n\", report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is similar than before. I will go back to CountVectorizer but try a different classifier (random forest).\n",
    "\n",
    "### 5.6 Model Iteration - Random Forest, Oversample, Count Vectorizer, Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vectorizer',\n",
       "                 CountVectorizer(tokenizer=<bound method TweetTokenizer.tokenize of <nltk.tokenize.casual.TweetTokenizer object at 0x000002AC0A7C4220>>)),\n",
       "                ('oversample', RandomOverSampler(random_state=42)),\n",
       "                ('rfc', RandomForestClassifier(random_state=42))])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pipeline with Random Forest\n",
    "rfc_pipe = Pipeline([\n",
    "    ('vectorizer', CountVectorizer(tokenizer=tokenizer.tokenize)),\n",
    "    ('oversample', RandomOverSampler(random_state=42)),\n",
    "    ('rfc', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "rfc_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.72\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.82      0.79      1326\n",
      "           1       0.62      0.54      0.58       728\n",
      "\n",
      "    accuracy                           0.72      2054\n",
      "   macro avg       0.69      0.68      0.69      2054\n",
      "weighted avg       0.72      0.72      0.72      2054\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predict on the test data\n",
    "y_pred = rfc_pipe.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(\"Classification Report:\\n\", report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.7 Model iteration - Grid Search on baseline model for hyperparameter tuning\n",
    "Now, I will try a GridSearch to tune hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7395326192794547\n",
      "Best Hyperparameters: {'lr__C': 0.1, 'lr__max_iter': 100, 'lr__solver': 'liblinear', 'vectorizer__ngram_range': (1, 3)}\n"
     ]
    }
   ],
   "source": [
    "# Instantiate tweet tokenizer to later include in the pipeline\n",
    "tokenizer = TweetTokenizer()\n",
    "\n",
    "# Define the pipeline\n",
    "lr_pipe_grid = Pipeline([\n",
    "    ('vectorizer', CountVectorizer(tokenizer=tokenizer.tokenize, ngram_range=(1, 3))),\n",
    "    ('oversample', RandomOverSampler(random_state=42)),\n",
    "    ('lr', LogisticRegression(random_state=42))\n",
    "])\n",
    "\n",
    "# Define the hyperparameter grid\n",
    "param_grid = {\n",
    "    'vectorizer__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
    "    'lr__C': [0.1, 1, 10],\n",
    "    'lr__solver': ['liblinear', 'sag', 'saga'],\n",
    "    'lr__max_iter': [100, 1000, 10000]\n",
    "}\n",
    "\n",
    "# Perform grid search\n",
    "grid_search = GridSearchCV(lr_pipe_grid, param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test data using the best model\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"Best Hyperparameters:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vectorizer',\n",
       "                 CountVectorizer(ngram_range=(1, 3),\n",
       "                                 tokenizer=<function custom_tokenizer at 0x000002AC0B120310>)),\n",
       "                ('oversample', RandomOverSampler(random_state=42)),\n",
       "                ('lr',\n",
       "                 LogisticRegression(C=0.1, random_state=42,\n",
       "                                    solver='liblinear'))])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate lemmatizer and tokenizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "tokenizer = TweetTokenizer()\n",
    "\n",
    "# Instantiate tweet tokenizer to later include in the pipeline\n",
    "lr_pipe_tknzr = Pipeline([\n",
    "    ('vectorizer', CountVectorizer(tokenizer=custom_tokenizer, ngram_range=(1, 3))),\n",
    "    ('oversample', RandomOverSampler(random_state=42)),\n",
    "    ('lr', LogisticRegression(random_state=42, max_iter=100, C=0.1, solver=\"liblinear\"))\n",
    "])\n",
    "\n",
    "lr_pipe_tknzr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.73\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.82      0.80      1326\n",
      "           1       0.63      0.57      0.60       728\n",
      "\n",
      "    accuracy                           0.73      2054\n",
      "   macro avg       0.70      0.70      0.70      2054\n",
      "weighted avg       0.73      0.73      0.73      2054\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predict on the test data\n",
    "y_pred = lr_pipe_tknzr.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(\"Classification Report:\\n\", report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hyperparameter tuning of my linear regression model resulted in better precision, recall and f1-scores of 0.73.\n",
    "### 5.8 Model iteration - Hyperparameter tuning random forest\n",
    "I will try another hyperparameter tuning of the random forest model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'rf__max_depth': None, 'rf__min_samples_leaf': 2, 'rf__min_samples_split': 5, 'rf__n_estimators': 200, 'vectorizer__ngram_range': (1, 2)}\n"
     ]
    }
   ],
   "source": [
    "# Instantiate tweet tokenizer to later include in the pipeline\n",
    "tokenizer = TweetTokenizer()\n",
    "\n",
    "# Define the pipeline\n",
    "rf_pipe_grid = Pipeline([\n",
    "    ('vectorizer', CountVectorizer(tokenizer=tokenizer.tokenize, ngram_range=(1, 3))),\n",
    "    ('oversample', RandomOverSampler(random_state=42)),\n",
    "    ('rf', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "# Define the hyperparameter grid\n",
    "param_grid_rf = {\n",
    "    'vectorizer__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
    "    'rf__n_estimators': [50, 100, 200],\n",
    "    'rf__max_depth': [None, 10, 20],\n",
    "    'rf__min_samples_split': [2, 5, 10],\n",
    "    'rf__min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Perform grid search\n",
    "grid_search = GridSearchCV(rf_pipe_grid, param_grid_rf, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test data using the best model\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"Best Hyperparameters:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vectorizer',\n",
       "                 CountVectorizer(ngram_range=(1, 2),\n",
       "                                 tokenizer=<bound method TweetTokenizer.tokenize of <nltk.tokenize.casual.TweetTokenizer object at 0x000002AC0A2DD9D0>>)),\n",
       "                ('oversample', RandomOverSampler(random_state=42)),\n",
       "                ('rfc',\n",
       "                 RandomForestClassifier(min_samples_leaf=2, min_samples_split=5,\n",
       "                                        n_estimators=200, random_state=42))])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pipeline with Random Forest\n",
    "rfc_pipe_tuned = Pipeline([\n",
    "    ('vectorizer', CountVectorizer(tokenizer=tokenizer.tokenize, ngram_range=(1,2))),\n",
    "    ('oversample', RandomOverSampler(random_state=42)),\n",
    "    ('rfc', RandomForestClassifier(random_state=42, max_depth=None, min_samples_leaf=2, \n",
    "                                  min_samples_split=5, n_estimators=200))\n",
    "])\n",
    "rfc_pipe_tuned.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.74\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.87      0.81      1326\n",
      "           1       0.68      0.50      0.58       728\n",
      "\n",
      "    accuracy                           0.74      2054\n",
      "   macro avg       0.72      0.68      0.69      2054\n",
      "weighted avg       0.73      0.74      0.73      2054\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predict on the test data\n",
    "y_pred = rfc_pipe_tuned.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(\"Classification Report:\\n\", report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 Model evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy of 74% indicates that the model correctly predicts the positive sentiment for approximately 74% of the tweets in the dataset. However, since my primary interest is in positive sentiment, this general accuracy might not be as crucial as the model's performance in detecting positive sentiment.\n",
    "\n",
    "Precision (Positive Class 0): Precision measures the proportion of true positive predictions among all positive predictions. In this case, for class 0 (positive sentiment), it's 0.76. This means that when the model predicts positive sentiment, it's correct 76% of the time. This high precision suggests that the model is reliable in identifying positive sentiment tweets.\n",
    "\n",
    "Recall (Positive Class 0): Recall (Sensitivity) measures the proportion of true positive predictions among all actual positive instances. For class 0, it's 0.87, indicating that the model captures 87% of the actual positive sentiment tweets. This high recall means that the model is effective at identifying the majority of positive sentiment tweets.\n",
    "\n",
    "F1-score (Positive Class 0): The F1-score, which is the harmonic mean of precision and recall, for class 0 is 0.81. This score confirms the overall effectiveness of the model in identifying positive sentiments.\n",
    "\n",
    "Limitations:\n",
    "\n",
    "Class Imbalance: While the model performs well in identifying positive sentiment, it's important to be aware of the class imbalance. There are more positive tweets (class 0) than negative tweets (class 1), which can affect the model's performance on the minority class (class 1). However, since my primary focus is on positive sentiments, this imbalance may not be a significant concern.\n",
    "\n",
    "Performance on Negative Sentiment (Class 1): Given the emphasis on positive sentiments, it's acceptable that the model may not perform as well in detecting negative sentiment tweets (class 1). The lower recall (0.50) for class 1 indicates that the model may miss some negative tweets, but this might not be a critical issue for our business objective.\n",
    "\n",
    "In conclusion, the primary goal is to focus on identifying positive sentiments and the model is performing well in terms of precision and recall for positive sentiment tweets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
